@page "/"
@using OpenAI_API
@using OpenAI_API.Chat
@using System.Text
@using Microsoft.CognitiveServices.Speech
@using NAudio.Wave


<PageTitle>Index</PageTitle>

@if (QuickAndDirtyApiKeys.KeysAreSet)
{

	<button type="button" class="btn btn-primary" @onclick="RecordQuestion">Record</button>
	@if (IsRecording)
	{
		<div>Recording...</div>
	}

		<div class="input-group">
			<input type="text" class="form-control" @bind="QuestionForChatGPT"/>
		</div>


		<button type="button" class="btn btn-primary" @onclick="AskChatGPT">Frag sände</button>

	@if (GptIsThinking)
	{
		<div>ChatGPT dänkt nache....</div>
	}

		<div>
			<textarea @bind="Answers" cols="200" rows="400"></textarea>
		</div>
}
else
{
	<div>API Keys fehlen noch...</div>
}

@code
{
	private OpenAIAPI? api = null; 
	private Conversation? chat = null;
    private SpeechConfig? config = null;

	public bool IsRecording { get; set; } = false;
	public string QuestionForChatGPT { get; set; } = "Drück doch eifach uf Record";
	public string Answers { get; set; } = string.Empty;
	public bool GptIsThinking { get; set; } = false;


	protected override void OnInitialized()
	{
		if (QuickAndDirtyApiKeys.KeysAreSet)
		{
			api = new OpenAIAPI(QuickAndDirtyApiKeys.OpenAiKey);
			chat = api.Chat.CreateConversation();
	        chat.AppendSystemMessage("Du bist eine Marketing-Assistentin names Leni. Du wohnst in Schattdorf und magst Tiere, Reisen und lange Spatziergänge. Dein liebster Schnupfspruch ist: als er gerade gerade war, knickte er ein, was schade war.");
			config = SpeechConfig.FromSubscription("5553e80a837b4f0584f93878fdcc23d6", "switzerlandnorth");
			config.SpeechSynthesisLanguage = "de-CH";
	        config.SpeechSynthesisVoiceName = "de-CH-LeniNeural";
		}

		base.OnInitialized();
	}


	private async Task AskChatGPT()
	{
		GptIsThinking = true;
		Answers += $"\nFrag: {QuestionForChatGPT}"; 
		chat.AppendUserInput(QuestionForChatGPT);
		var response =  await chat.GetResponseFromChatbot();

		Answers += $"\nAntwort: {response}";
		GptIsThinking = false;

		InvokeAsync(StateHasChanged);

		await TextToSpeech(response);

	}



	private async Task RecordQuestion()
	{
		IsRecording = true;
		InvokeAsync(StateHasChanged);

	

	// Creates a speech recognizer using microphone as audio input.
        using (var recognizer = new SpeechRecognizer(config, "de-CH"))
        {

            var result = await recognizer.RecognizeOnceAsync().ConfigureAwait(false);

            // Checks result.

            if (result.Reason == ResultReason.RecognizedSpeech)
            {
	            IsRecording = false;
	            QuestionForChatGPT = result.Text;

	            await AskChatGPT();

            }
            else if (result.Reason == ResultReason.NoMatch)
            {
	            QuestionForChatGPT = "hani nid verstandä";
            }
            else if (result.Reason == ResultReason.Canceled)
            {
	            StringBuilder sb = new StringBuilder();
                var cancellation = CancellationDetails.FromResult(result);
                sb.AppendLine($"CANCELED: Reason={cancellation.Reason}");
                if (cancellation.Reason == CancellationReason.Error)
                {
                    sb.AppendLine($"CANCELED: ErrorCode={cancellation.ErrorCode}");
                    sb.AppendLine($"CANCELED: ErrorDetails={cancellation.ErrorDetails}");
                    sb.AppendLine($"CANCELED: Did you update the subscription info?");
                }

	            QuestionForChatGPT = sb.ToString();
            }

        }
		
		IsRecording = false;
	}

    private async Task TextToSpeech(string lastText)
    {
        
        try
        {
            // Creates a speech synthesizer.
            using (var synthesizer = new SpeechSynthesizer(config, null))
            {
                // Receive a text from TextForSynthesis text box and synthesize it to speaker.
                using (var result = await synthesizer.SpeakTextAsync(lastText).ConfigureAwait(false))
                {
                    // Checks result.
                    if (result.Reason == ResultReason.SynthesizingAudioCompleted)
                    {
                        // Since native playback is not yet supported on UWP (currently only supported on Windows/Linux Desktop),
                        // use the WinRT API to play audio here as a short term solution.
                        using (var audioStream = AudioDataStream.FromResult(result))
                        {

	
                            // Save synthesized audio data as a wave file and use MediaPlayer to play it
                            var filePath = "outputaudio.wav";
                            
                            await audioStream.SaveToWaveFileAsync(filePath);
                            using (var audioFile = new AudioFileReader(filePath))
	                        using(var outputDevice = new WaveOutEvent())
	                        {
		                        outputDevice.Init(audioFile);
		                        outputDevice.Play();
		                        while (outputDevice.PlaybackState == PlaybackState.Playing)
		                        {
			                        Thread.Sleep(1000);
		                        }
	                        }
                        }
                    }
                    else if (result.Reason == ResultReason.Canceled)
                    {
                        var cancellation = SpeechSynthesisCancellationDetails.FromResult(result);

                        StringBuilder sb = new StringBuilder();
                        sb.AppendLine($"CANCELED: Reason={cancellation.Reason}");
                        sb.AppendLine($"CANCELED: ErrorCode={cancellation.ErrorCode}");
                        sb.AppendLine($"CANCELED: ErrorDetails=[{cancellation.ErrorDetails}]");
                    }
                }
            }
        }
        catch (Exception ex)
        {
 
        }

    }

}
